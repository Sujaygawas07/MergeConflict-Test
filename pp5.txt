Assignment=1
from sklearn import datasets
import warnings
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
warnings.filterwarnings('ignore')
from sklearn.linear_model import LinearRegression

data=datasets.load_boston()
df=pd.DataFrame(data.data,columns=data.feature_names)
df['price']=data.target

df.info()
df.isnull().sum()
df.describe()
df.shape

fig=plt.figure(figsize=(10,10))
df.boxplot()

sns.boxplot(df["RM"])

plt.hist(df["RM"])

df["RM"].value_counts()

sns.scatterplot(df["LSTAT"],df["price"])

fig=plt.subplots(figsize=(10,10))
sns.heatmap(df.corr(),annot=True,cmap="Blues")

		***ASS 2***

import pandas as pd
dataset = pd.read_csv('IMDB_Dataset.csv')
dataset.head()

 import matplotlib.pyplot as plt
import tensorflow.keras as tf
from keras.preprocessing.text import Tokenizer

tokenizer1 = Tokenizer(oov_token="<nothing>")

tokenizer1.fit_on_texts(dataset["review"])

tokenizer1.word_index
tokenizer1.word_counts
tokenizer1.document_count

dataset["review"]=tokenizer1.texts_to_sequences(dataset["review"])
dataset.head()

from keras.utils import pad_sequences
seq_df=pd.DataFrame(pad_sequences(dataset["review"]))

dataset=dataset.join(seq_df)

dataset.drop(["review"],axis=1,inplace=True)
dataset.head()

dataset["sentiment"].value_counts()

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
dataset["sentiment"]=le.fit_transform(dataset["sentiment"])
from sklearn.model_selection import train_test_split

y=dataset["sentiment"]
x=dataset.iloc[:,1:]

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)

m1=tf.Sequential()
m1.add(tf.layers.Input(shape=(2493,)))
m1.add(tf.layers.Dense(50,activation="relu",kernel_initializer="he_uniform"))
m1.add(tf.layers.Dense(1,activation="sigmoid",kernel_initializer="he_uniform"))
m1.summary()

m1.compile(optimizer="adam",loss="binary_crossentropy",metrics=["accuracy"])

obj1=m1.fit(x=x_train,y=y_train,epochs=30,batch_size=64,validation_data=(x_test,y_test))

y_pred=m1.predict(x_test)

from sklearn.metrics import accuracy_score
accuracy=accuracy_score(y_test,y_pred.round())
accuracy

               ***ASS 3***

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from keras.datasets import fashion_mnist    
import tensorflow.keras as tk
get_ipython().run_line_magic ('matplotlib', 'inline')

from keras.datasets import fashion_mnist

(x_train,y_train),(x_test,y_test)=fashion_mnist.load_data()

x_train.shape,x_test.shape

import matplotlib.pyplot as plt
plt.figure(figsize=(20,20))
for i in range (1,200):
    plt.subplot(20,10,i)
    plt.imshow(x_train[i],cmap="Blues")
plt.show()

import tensorflow.keras as tf

m1=tf.Sequential()
m1.add(tf.layers.Conv2D(32,3,3,input_shape=(28,28,1),activation="relu"))
m1.add(tf.layers.MaxPooling2D(pool_size=(2,2)))

m1.add(tf.layers.Flatten())

m1.add(tf.layers.Dense(50,activation="relu"))
m1.add(tf.layers.Dense(10,activation="sigmoid"))
m1.summary()

m1.compile(optimizer="adam",loss="sparse_categorical_crossentropy",metrics=["accuracy"])


m1.fit(x_train,y_train,epochs=50,verbose=1,batch_size=1000,validation_data=(x_test,y_test))

e=m1.evaluate(x_test,y_test)

e[1]

y_pred=np.argmax(m1.predict(x_test),axis=-1)
l=10
w=10
fig, axes = plt.subplots(l, w, figsize=(20, 20))
axes = axes.ravel()
for i in np.arange(0, l*w):
    axes[i].imshow(x_test[i].reshape(28, 28))
    axes[i].set_title("predicted label: {}\nactual label: {}".format(y_pred[i], y_test[i]))
    axes[i].axis("off")
plt.subplots_adjust(wspace=0.75)
plt.show()


           ***ASS 4***


import pandas as pd

data=pd.read_csv("Google_Stock_Price_Train.csv")

data.head()

training_set=data.iloc[:,1:2].values
training_set


from sklearn.preprocessing import MinMaxScaler


sc=MinMaxScaler()
trainset=sc.fit_transform(training_set)
trainset

trainset.shape

trainset.reshape(1258,1,1)

import matplotlib.pyplot as plt
fig=plt.figure(figsize=(10,10))
plt.subplots_adjust(top=1.35,bottom=1.12)
data["Open"].plot()
plt.ylabel("open")
plt.title("Sales Open")

testdata=pd.read_csv("Google_Stock_Price_Test.csv")

testdata.head()

testset=testdata.iloc[:,1:2]
testset

testset=sc.fit_transform(testset)

testset.shape

testset.reshape(20,1,1)

import tensorflow.keras as tf

m1=tf.Sequential()
m1.add(tf.layers.LSTM(5,activation="softmax",input_shape=(None,1)))
m1.add(tf.layers.Dense(1))
m1.summary()



